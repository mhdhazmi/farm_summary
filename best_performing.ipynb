{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loading_geo_data():\n",
    "    import geopandas as gpd\n",
    "    import fiona\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Path to your .gdb file\n",
    "    file_path = \"./HSR_KSATD2.gdb/\"\n",
    "\n",
    "    # Specify the layer name you're interested in\n",
    "    layer_name = 'Farms'\n",
    "    # Read the layer into a GeoDataFrame\n",
    "    df_farms = gpd.read_file(file_path, layer=layer_name)\n",
    "    layer_name = 'Property'\n",
    "    df_property = gpd.read_file(file_path, layer=layer_name)\n",
    "    layer_name = 'Wells'\n",
    "    # Read the layer into a GeoDataFrame\n",
    "    df_wells = gpd.read_file(file_path, layer=layer_name)\n",
    "    return df_farms, df_property, df_wells\n",
    "\n",
    "\n",
    "df_farms, df_property, df_wells = loading_geo_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/c6__5rb9295_cgz_cndc2knw0000gn/T/ipykernel_69054/3090629733.py:25: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df[col] = df[col].replace(0,df[col].mode()[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farm_id</th>\n",
       "      <th>well_possession_type_1</th>\n",
       "      <th>well_possession_type_2</th>\n",
       "      <th>well_is_active_1</th>\n",
       "      <th>well_is_active_2</th>\n",
       "      <th>well_irrigation_source_1</th>\n",
       "      <th>well_irrigation_source_2</th>\n",
       "      <th>well_irrigation_source_4</th>\n",
       "      <th>well_irrigation_source_5</th>\n",
       "      <th>well_irrigation_source_6</th>\n",
       "      <th>...</th>\n",
       "      <th>well_irrigation_source_10_percentage</th>\n",
       "      <th>well_irrigation_source_12_percentage</th>\n",
       "      <th>well_irrigation_type_1.0_percentage</th>\n",
       "      <th>well_irrigation_type_2.0_percentage</th>\n",
       "      <th>well_irrigation_type_3.0_percentage</th>\n",
       "      <th>well_irrigation_type_4.0_percentage</th>\n",
       "      <th>well_irrigation_type_6.0_percentage</th>\n",
       "      <th>well_irrigation_type_7.0_percentage</th>\n",
       "      <th>sprinklers_count</th>\n",
       "      <th>sprinklers_count_kw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_00_000002</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_00_000003</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_00_000006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_00_000008</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_00_000009</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        farm_id  well_possession_type_1  well_possession_type_2  \\\n",
       "0  01_00_000002                       5                       0   \n",
       "1  01_00_000003                       5                       0   \n",
       "2  01_00_000006                       1                       0   \n",
       "3  01_00_000008                       2                       0   \n",
       "4  01_00_000009                       2                       0   \n",
       "\n",
       "   well_is_active_1  well_is_active_2  well_irrigation_source_1  \\\n",
       "0                 5                 0                         4   \n",
       "1                 5                 0                         5   \n",
       "2                 1                 0                         0   \n",
       "3                 2                 0                         1   \n",
       "4                 0                 2                         2   \n",
       "\n",
       "   well_irrigation_source_2  well_irrigation_source_4  \\\n",
       "0                         1                         0   \n",
       "1                         0                         0   \n",
       "2                         1                         0   \n",
       "3                         1                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   well_irrigation_source_5  well_irrigation_source_6  ...  \\\n",
       "0                         0                         0  ...   \n",
       "1                         0                         0  ...   \n",
       "2                         0                         0  ...   \n",
       "3                         0                         0  ...   \n",
       "4                         0                         0  ...   \n",
       "\n",
       "   well_irrigation_source_10_percentage  well_irrigation_source_12_percentage  \\\n",
       "0                                   0.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   well_irrigation_type_1.0_percentage  well_irrigation_type_2.0_percentage  \\\n",
       "0                                  0.8                                  0.2   \n",
       "1                                  1.0                                  0.0   \n",
       "2                                  1.0                                  0.0   \n",
       "3                                  0.5                                  0.0   \n",
       "4                                  1.0                                  0.0   \n",
       "\n",
       "   well_irrigation_type_3.0_percentage  well_irrigation_type_4.0_percentage  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.5                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   well_irrigation_type_6.0_percentage  well_irrigation_type_7.0_percentage  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   sprinklers_count  sprinklers_count_kw  \n",
       "0                 5                  125  \n",
       "1                 5                  125  \n",
       "2                 1                   25  \n",
       "3                 2                   50  \n",
       "4                 2                   50  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_wells = df_wells.rename(\n",
    "    columns={\n",
    "        \"HSRCode\": \"well_id\",\n",
    "        \"OB_HSRCode\": \"farm_id\",\n",
    "        \"PossessionType\": \"well_possession_type\",\n",
    "        \"IsActive\": \"well_is_active\",\n",
    "        \"IrragationSource\": \"well_irrigation_source\",\n",
    "        \"IrrigationType\": \"well_irrigation_type\",\n",
    "        \"X\": \"well_longitude\",\n",
    "        \"Y\": \"well_latitude\",\n",
    "        \"Region\": \"well_region\",\n",
    "    }\n",
    ")\n",
    "df_wells = df_wells[['well_id', 'farm_id', 'well_possession_type', 'well_is_active', 'well_irrigation_source', 'well_irrigation_type',]]\n",
    "df_wells['well_possession_type'] = df_wells['well_possession_type'].astype('category')\n",
    "df_wells['well_is_active'] = df_wells['well_is_active'].astype('category')\n",
    "df_wells['well_irrigation_source'] = df_wells['well_irrigation_source'].astype('category')\n",
    "df_wells['well_irrigation_type'] = df_wells['well_irrigation_type'].astype('category')\n",
    "categorical_columns = df_wells.drop(columns=['farm_id']).select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "def fill_missing_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        df[col] = df[col].replace(0,df[col].mode()[0])\n",
    "\n",
    "fill_missing_categorical(df_wells, categorical_columns)\n",
    "\n",
    "well_count = df_wells.groupby(\"farm_id\").agg(well_count=pd.NamedAgg(column=\"well_id\", aggfunc=\"count\")).reset_index()\n",
    "df_wells = df_wells.drop(columns=['well_id'])\n",
    "\n",
    "df_wells_summary = pd.get_dummies(df_wells, columns=['well_possession_type','well_is_active','well_irrigation_source', 'well_irrigation_type'], dtype=int)\n",
    "df_wells_summary = df_wells_summary.groupby(\"farm_id\").sum().reset_index()\n",
    "df_wells_summary = pd.merge(df_wells_summary, well_count, on='farm_id')\n",
    "df_wells_summary\n",
    "\n",
    "\n",
    "# Calculate percentages for irrigation sources and types\n",
    "for col in df_wells_summary.columns:\n",
    "    if col.startswith('well_') and col != 'well_count':\n",
    "        df_wells_summary[f'{col}_percentage'] = df_wells_summary[col] / df_wells_summary['well_count']\n",
    "\n",
    "\n",
    "df_wells_summary['sprinklers_count'] = df_wells_summary['well_count']\n",
    "df_wells_summary['sprinklers_count_kw'] = df_wells_summary['well_count'] * 25\n",
    "\n",
    "df_wells_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/c6__5rb9295_cgz_cndc2knw0000gn/T/ipykernel_69054/2883810874.py:42: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df_farms[col] = df_farms[col].replace(0, df_farms[col].mode()[0])\n",
      "/var/folders/dw/c6__5rb9295_cgz_cndc2knw0000gn/T/ipykernel_69054/2883810874.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_farms_summary = df_farms.groupby('farm_id').agg(agg_dict).rename(columns={'activity_id': 'activity_count', 'crop_type': 'unique_crop_types_count'}).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farm_id</th>\n",
       "      <th>activity_count</th>\n",
       "      <th>unique_crop_types_count</th>\n",
       "      <th>total_area_hectares</th>\n",
       "      <th>productive_trees_count</th>\n",
       "      <th>protected_house_count</th>\n",
       "      <th>plantations_count</th>\n",
       "      <th>activity_status_1</th>\n",
       "      <th>activity_status_3</th>\n",
       "      <th>activity_status_4</th>\n",
       "      <th>...</th>\n",
       "      <th>farming_season_4.0</th>\n",
       "      <th>protected_house_type_1.0</th>\n",
       "      <th>protected_house_type_2.0</th>\n",
       "      <th>protected_house_type_3.0</th>\n",
       "      <th>protected_house_type_4.0</th>\n",
       "      <th>protected_house_type_6.0</th>\n",
       "      <th>protected_house_type_7.0</th>\n",
       "      <th>plantations_type_1.0</th>\n",
       "      <th>plantations_type_2.0</th>\n",
       "      <th>plantations_type_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_00_000002</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>55.035575</td>\n",
       "      <td>594.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_00_000003</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>67.494602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_00_000006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.682688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_00_000008</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>46.750421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_00_000009</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.911888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17365</th>\n",
       "      <td>13_00_014341</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>30.365888</td>\n",
       "      <td>4564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17366</th>\n",
       "      <td>13_00_014422</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.711515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17367</th>\n",
       "      <td>13_00_016808</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60.445241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "      <td>13_00_016813</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>87.881187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17369</th>\n",
       "      <td>13_00_016815</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84.865659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17370 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            farm_id  activity_count  unique_crop_types_count  \\\n",
       "0      01_00_000002               6                        2   \n",
       "1      01_00_000003               5                        1   \n",
       "2      01_00_000006               1                        1   \n",
       "3      01_00_000008              11                        3   \n",
       "4      01_00_000009               2                        1   \n",
       "...             ...             ...                      ...   \n",
       "17365  13_00_014341               4                        2   \n",
       "17366  13_00_014422               1                        1   \n",
       "17367  13_00_016808               1                        1   \n",
       "17368  13_00_016813               3                        2   \n",
       "17369  13_00_016815               2                        1   \n",
       "\n",
       "       total_area_hectares  productive_trees_count  protected_house_count  \\\n",
       "0                55.035575                   594.0                    0.0   \n",
       "1                67.494602                     0.0                    0.0   \n",
       "2                30.682688                     0.0                    0.0   \n",
       "3                46.750421                     0.0                    0.0   \n",
       "4                27.911888                     0.0                    0.0   \n",
       "...                    ...                     ...                    ...   \n",
       "17365            30.365888                  4564.0                    0.0   \n",
       "17366            13.711515                     0.0                    0.0   \n",
       "17367            60.445241                     0.0                    0.0   \n",
       "17368            87.881187                     0.0                    0.0   \n",
       "17369            84.865659                     0.0                    0.0   \n",
       "\n",
       "       plantations_count  activity_status_1  activity_status_3  \\\n",
       "0                    0.0                  4                  1   \n",
       "1                    0.0                  5                  0   \n",
       "2                    0.0                  1                  0   \n",
       "3                    0.0                  5                  6   \n",
       "4                    0.0                  2                  0   \n",
       "...                  ...                ...                ...   \n",
       "17365                0.0                  4                  0   \n",
       "17366                0.0                  1                  0   \n",
       "17367                0.0                  1                  0   \n",
       "17368                0.0                  3                  0   \n",
       "17369                0.0                  1                  0   \n",
       "\n",
       "       activity_status_4  ...  farming_season_4.0  protected_house_type_1.0  \\\n",
       "0                      1  ...                   2                         6   \n",
       "1                      0  ...                   0                         5   \n",
       "2                      0  ...                   0                         1   \n",
       "3                      0  ...                   6                        11   \n",
       "4                      0  ...                   0                         2   \n",
       "...                  ...  ...                 ...                       ...   \n",
       "17365                  0  ...                   0                         4   \n",
       "17366                  0  ...                   0                         1   \n",
       "17367                  0  ...                   0                         1   \n",
       "17368                  0  ...                   0                         3   \n",
       "17369                  1  ...                   1                         2   \n",
       "\n",
       "       protected_house_type_2.0  protected_house_type_3.0  \\\n",
       "0                             0                         0   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "...                         ...                       ...   \n",
       "17365                         0                         0   \n",
       "17366                         0                         0   \n",
       "17367                         0                         0   \n",
       "17368                         0                         0   \n",
       "17369                         0                         0   \n",
       "\n",
       "       protected_house_type_4.0  protected_house_type_6.0  \\\n",
       "0                             0                         0   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "...                         ...                       ...   \n",
       "17365                         0                         0   \n",
       "17366                         0                         0   \n",
       "17367                         0                         0   \n",
       "17368                         0                         0   \n",
       "17369                         0                         0   \n",
       "\n",
       "       protected_house_type_7.0  plantations_type_1.0  plantations_type_2.0  \\\n",
       "0                             0                     0                     0   \n",
       "1                             0                     0                     0   \n",
       "2                             0                     0                     0   \n",
       "3                             0                     0                     0   \n",
       "4                             0                     0                     0   \n",
       "...                         ...                   ...                   ...   \n",
       "17365                         0                     0                     0   \n",
       "17366                         0                     0                     0   \n",
       "17367                         0                     0                     0   \n",
       "17368                         0                     0                     0   \n",
       "17369                         0                     0                     0   \n",
       "\n",
       "       plantations_type_3.0  \n",
       "0                         6  \n",
       "1                         5  \n",
       "2                         1  \n",
       "3                        11  \n",
       "4                         2  \n",
       "...                     ...  \n",
       "17365                     4  \n",
       "17366                     1  \n",
       "17367                     1  \n",
       "17368                     3  \n",
       "17369                     2  \n",
       "\n",
       "[17370 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "rename_dict = {\n",
    "    'HSRCode': 'activity_id',\n",
    "    'OB_HSRCode': 'farm_id',\n",
    "    'ActivityStatus': 'activity_status',\n",
    "    'FarmType': 'farm_type',\n",
    "    'MainCropsType': 'main_crop_type',\n",
    "    'CropsType': 'crop_type',\n",
    "    'IrragationSource': 'irrigation_source',\n",
    "    'IrragationType': 'irrigation_type',\n",
    "    'FarmingSeason': 'farming_season',\n",
    "    'TotalArea': 'total_area_hectares',\n",
    "    'ProductiveTreesNo': 'productive_trees_count',\n",
    "    'ProtectedHouseNo': 'protected_house_count',\n",
    "    'ProtectedHouseType': 'protected_house_type',\n",
    "    'PlantationsNo': 'plantations_count',\n",
    "    'PlantationsType': 'plantations_type'\n",
    "}\n",
    "df_farms = df_farms.rename(columns={k: v for k, v in rename_dict.items() if k in df_farms.columns})\n",
    "df_farms['total_area_hectares'] = df_farms['total_area_hectares'].astype(float)\n",
    "df_farms['productive_trees_count'] = df_farms['productive_trees_count'].astype(float)\n",
    "df_farms['protected_house_count'] = df_farms['protected_house_count'].astype(float)\n",
    "df_farms['plantations_count'] = df_farms['plantations_count'].astype(float)\n",
    "df_farms['activity_id'] = df_farms['activity_id'].astype('category')\n",
    "df_farms['farm_id'] = df_farms['farm_id'].astype('category')\n",
    "df_farms['activity_status'] = df_farms['activity_status'].astype('category')\n",
    "df_farms['farm_type'] = df_farms['farm_type'].astype('category')\n",
    "df_farms['main_crop_type'] = df_farms['main_crop_type'].astype('category')\n",
    "df_farms['crop_type'] = df_farms['crop_type'].astype('category')\n",
    "df_farms['irrigation_source'] = df_farms['irrigation_source'].astype('category')\n",
    "df_farms['irrigation_type'] = df_farms['irrigation_type'].astype('category')\n",
    "df_farms['farming_season'] = df_farms['farming_season'].astype('category')\n",
    "df_farms['protected_house_type'] = df_farms['protected_house_type'].astype('category')\n",
    "df_farms['plantations_type'] = df_farms['plantations_type'].astype('category')\n",
    "\n",
    "\n",
    "numeric_columns = df_farms.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "\n",
    "categorical_columns = df_farms.drop(columns=['farm_id', 'activity_id', 'crop_type']).select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for col in categorical_columns:\n",
    "    df_farms[col] = df_farms[col].fillna(df_farms[col].mode()[0])\n",
    "    df_farms[col] = df_farms[col].replace(0, df_farms[col].mode()[0])\n",
    "\n",
    "# # Create dummy variables for categorical columns\n",
    "df_farms = pd.get_dummies(df_farms, columns=categorical_columns, prefix_sep='_', dtype=int)\n",
    "# unique_crops = df_farms.groupby('farm_id')['crop_type'].nunique().reset_index()\n",
    "# Prepare aggregation dictionary\n",
    "agg_dict = {\n",
    "    'activity_id': 'nunique',\n",
    "    'crop_type': 'nunique',\n",
    "\n",
    "}\n",
    "agg_dict.update({col: 'sum' for col in numeric_columns})\n",
    "\n",
    "# Add dummy columns to aggregation dictionary\n",
    "dummy_columns = [col for col in df_farms.columns if '_' in col and col not in ['farm_id', 'activity_id', 'crop_type'] and col not in numeric_columns]\n",
    "agg_dict.update({col: 'sum' for col in dummy_columns})\n",
    "\n",
    "# # Group by farm_id and aggregate\n",
    "df_farms_summary = df_farms.groupby('farm_id').agg(agg_dict).rename(columns={'activity_id': 'activity_count', 'crop_type': 'unique_crop_types_count'}).reset_index()\n",
    "\n",
    "df_farms_summary = df_farms_summary.drop(columns=[\"X\", \"Y\", \"SHAPE_Length\", \"SHAPE_Area\",])\n",
    "df_farms_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farm_id</th>\n",
       "      <th>property_area</th>\n",
       "      <th>property_main_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05_00_000030</td>\n",
       "      <td>3.565259e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05_00_000090</td>\n",
       "      <td>3.681615e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05_00_000051</td>\n",
       "      <td>2.555279e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05_00_000067</td>\n",
       "      <td>1.168098e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05_00_000177</td>\n",
       "      <td>1.337747e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18308</th>\n",
       "      <td>06_00_008951</td>\n",
       "      <td>6.254972e+05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18309</th>\n",
       "      <td>06_00_008965</td>\n",
       "      <td>8.418189e+05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18310</th>\n",
       "      <td>06_00_008968</td>\n",
       "      <td>7.502167e+05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18311</th>\n",
       "      <td>06_00_009342</td>\n",
       "      <td>1.697147e+06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18312</th>\n",
       "      <td>06_00_012125</td>\n",
       "      <td>1.363686e+06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18313 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            farm_id  property_area  property_main_type\n",
       "0      05_00_000030   3.565259e+06                 3.0\n",
       "1      05_00_000090   3.681615e+06                 3.0\n",
       "2      05_00_000051   2.555279e+06                 3.0\n",
       "3      05_00_000067   1.168098e+06                 3.0\n",
       "4      05_00_000177   1.337747e+06                 3.0\n",
       "...             ...            ...                 ...\n",
       "18308  06_00_008951   6.254972e+05                 1.0\n",
       "18309  06_00_008965   8.418189e+05                 1.0\n",
       "18310  06_00_008968   7.502167e+05                 1.0\n",
       "18311  06_00_009342   1.697147e+06                 1.0\n",
       "18312  06_00_012125   1.363686e+06                 1.0\n",
       "\n",
       "[18313 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_property = (\n",
    "    df_property[[\"OB_HSRCode\", \"SHAPE_Area\", \"MainType\"]].rename(\n",
    "        columns={\n",
    "            \"OB_HSRCode\": \"farm_id\",\n",
    "            \"SHAPE_Area\": \"property_area\",\n",
    "            \"MainType\": \"property_main_type\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df_visits = pd.read_csv(\"./processed_data/visits_final.csv\", usecols=['farm_id','total_electrical_load_kw'])\n",
    "df_visits_processed = df_visits[(df_visits['total_electrical_load_kw'] > 0) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farm_id</th>\n",
       "      <th>property_area</th>\n",
       "      <th>property_main_type</th>\n",
       "      <th>activity_count</th>\n",
       "      <th>unique_crop_types_count</th>\n",
       "      <th>total_area_hectares</th>\n",
       "      <th>productive_trees_count</th>\n",
       "      <th>protected_house_count</th>\n",
       "      <th>plantations_count</th>\n",
       "      <th>activity_status_1</th>\n",
       "      <th>...</th>\n",
       "      <th>well_irrigation_source_12_percentage</th>\n",
       "      <th>well_irrigation_type_1.0_percentage</th>\n",
       "      <th>well_irrigation_type_2.0_percentage</th>\n",
       "      <th>well_irrigation_type_3.0_percentage</th>\n",
       "      <th>well_irrigation_type_4.0_percentage</th>\n",
       "      <th>well_irrigation_type_6.0_percentage</th>\n",
       "      <th>well_irrigation_type_7.0_percentage</th>\n",
       "      <th>sprinklers_count</th>\n",
       "      <th>sprinklers_count_kw</th>\n",
       "      <th>total_electrical_load_kw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_00_000008</td>\n",
       "      <td>1.273708e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.750421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1492.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_00_000012</td>\n",
       "      <td>1.449119e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.246073</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>360.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_00_000014</td>\n",
       "      <td>1.710511e+06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.493831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>609.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_00_000016</td>\n",
       "      <td>1.171881e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.170176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1026.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_00_000017</td>\n",
       "      <td>2.063067e+06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.862922</td>\n",
       "      <td>683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>398.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>07_00_013777</td>\n",
       "      <td>1.064688e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.734726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>342.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>07_00_013781</td>\n",
       "      <td>5.385670e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.266395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>472.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>07_00_013868</td>\n",
       "      <td>2.351574e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.160858</td>\n",
       "      <td>5902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>342.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>07_00_013869</td>\n",
       "      <td>1.566152e+06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.228900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>398.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>07_00_013883</td>\n",
       "      <td>1.022357e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.582407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>398.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10871 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            farm_id  property_area  property_main_type  activity_count  \\\n",
       "0      01_00_000008   1.273708e+06                 1.0            11.0   \n",
       "1      01_00_000012   1.449119e+06                 1.0             3.0   \n",
       "2      01_00_000014   1.710511e+06                 5.0            14.0   \n",
       "3      01_00_000016   1.171881e+06                 1.0             4.0   \n",
       "4      01_00_000017   2.063067e+06                 3.0             3.0   \n",
       "...             ...            ...                 ...             ...   \n",
       "10866  07_00_013777   1.064688e+06                 1.0             1.0   \n",
       "10867  07_00_013781   5.385670e+05                 1.0             1.0   \n",
       "10868  07_00_013868   2.351574e+06                 1.0             6.0   \n",
       "10869  07_00_013869   1.566152e+06                 3.0             2.0   \n",
       "10870  07_00_013883   1.022357e+06                 1.0             1.0   \n",
       "\n",
       "       unique_crop_types_count  total_area_hectares  productive_trees_count  \\\n",
       "0                          3.0            46.750421                     0.0   \n",
       "1                          2.0            42.246073                   156.0   \n",
       "2                          1.0            96.493831                     0.0   \n",
       "3                          3.0            86.170176                     0.0   \n",
       "4                          1.0            61.862922                   683.0   \n",
       "...                        ...                  ...                     ...   \n",
       "10866                      1.0            82.734726                     0.0   \n",
       "10867                      1.0            41.266395                     0.0   \n",
       "10868                      3.0            81.160858                  5902.0   \n",
       "10869                      2.0            82.228900                     0.0   \n",
       "10870                      1.0            63.582407                     0.0   \n",
       "\n",
       "       protected_house_count  plantations_count  activity_status_1  ...  \\\n",
       "0                        0.0                0.0                5.0  ...   \n",
       "1                        0.0                0.0                2.0  ...   \n",
       "2                        0.0                0.0                6.0  ...   \n",
       "3                        0.0                0.0                4.0  ...   \n",
       "4                        0.0                0.0                1.0  ...   \n",
       "...                      ...                ...                ...  ...   \n",
       "10866                    0.0                0.0                1.0  ...   \n",
       "10867                    0.0                0.0                0.0  ...   \n",
       "10868                    0.0                0.0                6.0  ...   \n",
       "10869                    0.0                0.0                2.0  ...   \n",
       "10870                    0.0                0.0                1.0  ...   \n",
       "\n",
       "       well_irrigation_source_12_percentage  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       1.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "10866                                   0.0   \n",
       "10867                                   0.0   \n",
       "10868                                   0.0   \n",
       "10869                                   0.0   \n",
       "10870                                   0.0   \n",
       "\n",
       "       well_irrigation_type_1.0_percentage  \\\n",
       "0                                      0.5   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "...                                    ...   \n",
       "10866                                  1.0   \n",
       "10867                                  1.0   \n",
       "10868                                  1.0   \n",
       "10869                                  1.0   \n",
       "10870                                  1.0   \n",
       "\n",
       "       well_irrigation_type_2.0_percentage  \\\n",
       "0                                 0.000000   \n",
       "1                                 1.000000   \n",
       "2                                 0.000000   \n",
       "3                                 0.000000   \n",
       "4                                 0.666667   \n",
       "...                                    ...   \n",
       "10866                             0.000000   \n",
       "10867                             0.000000   \n",
       "10868                             0.000000   \n",
       "10869                             0.000000   \n",
       "10870                             0.000000   \n",
       "\n",
       "       well_irrigation_type_3.0_percentage  \\\n",
       "0                                 0.500000   \n",
       "1                                 0.000000   \n",
       "2                                 1.000000   \n",
       "3                                 1.000000   \n",
       "4                                 0.333333   \n",
       "...                                    ...   \n",
       "10866                             0.000000   \n",
       "10867                             0.000000   \n",
       "10868                             0.000000   \n",
       "10869                             0.000000   \n",
       "10870                             0.000000   \n",
       "\n",
       "       well_irrigation_type_4.0_percentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "...                                    ...   \n",
       "10866                                  0.0   \n",
       "10867                                  0.0   \n",
       "10868                                  0.0   \n",
       "10869                                  0.0   \n",
       "10870                                  0.0   \n",
       "\n",
       "       well_irrigation_type_6.0_percentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "...                                    ...   \n",
       "10866                                  0.0   \n",
       "10867                                  0.0   \n",
       "10868                                  0.0   \n",
       "10869                                  0.0   \n",
       "10870                                  0.0   \n",
       "\n",
       "       well_irrigation_type_7.0_percentage  sprinklers_count  \\\n",
       "0                                      0.0               2.0   \n",
       "1                                      0.0               3.0   \n",
       "2                                      0.0               3.0   \n",
       "3                                      0.0               2.0   \n",
       "4                                      0.0               3.0   \n",
       "...                                    ...               ...   \n",
       "10866                                  0.0               1.0   \n",
       "10867                                  0.0               1.0   \n",
       "10868                                  0.0               2.0   \n",
       "10869                                  0.0               2.0   \n",
       "10870                                  0.0               1.0   \n",
       "\n",
       "       sprinklers_count_kw  total_electrical_load_kw  \n",
       "0                     50.0                   1492.80  \n",
       "1                     75.0                    360.70  \n",
       "2                     75.0                    609.50  \n",
       "3                     50.0                   1026.15  \n",
       "4                     75.0                    398.00  \n",
       "...                    ...                       ...  \n",
       "10866                 25.0                    342.05  \n",
       "10867                 25.0                    472.60  \n",
       "10868                 50.0                    342.05  \n",
       "10869                 50.0                    398.00  \n",
       "10870                 25.0                    398.00  \n",
       "\n",
       "[10871 rows x 99 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Start with df_property as the base\n",
    "df_integrated = df_property.copy()\n",
    "# Merge with df_farms_summary\n",
    "df_integrated = df_integrated.merge(df_farms_summary, on='farm_id', how='left')\n",
    "\n",
    "# Merge with df_wells_summary\n",
    "df_integrated = df_integrated.merge(df_wells_summary, on='farm_id', how='left')\n",
    "\n",
    "\n",
    "# Merge with df_visits_processed\n",
    "df_integrated = df_integrated.merge(df_visits_processed, on='farm_id', how='right')\n",
    "df_integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['property_area', 'property_main_type', 'activity_count',\n",
      "       'unique_crop_types_count', 'total_area_hectares',\n",
      "       'productive_trees_count', 'protected_house_count', 'activity_status_1',\n",
      "       'activity_status_3', 'activity_status_4', 'activity_status_6',\n",
      "       'farm_type_1.0', 'farm_type_2.0', 'farm_type_6.0', 'farm_type_7.0',\n",
      "       'main_crop_type_1.0', 'main_crop_type_2.0', 'main_crop_type_4.0',\n",
      "       'main_crop_type_6.0', 'main_crop_type_8.0', 'main_crop_type_10.0',\n",
      "       'main_crop_type_15.0', 'irrigation_source_1.0', 'irrigation_source_2.0',\n",
      "       'irrigation_source_12.0', 'irrigation_type_1.0', 'irrigation_type_2.0',\n",
      "       'irrigation_type_3.0', 'irrigation_type_6.0', 'farming_season_1.0',\n",
      "       'farming_season_2.0', 'farming_season_3.0', 'farming_season_4.0',\n",
      "       'protected_house_type_1.0', 'plantations_type_3.0',\n",
      "       'well_possession_type_1', 'well_is_active_1',\n",
      "       'well_irrigation_source_1', 'well_irrigation_source_2',\n",
      "       'well_irrigation_type_1.0', 'well_irrigation_type_3.0', 'well_count',\n",
      "       'well_is_active_1_percentage', 'well_irrigation_source_1_percentage',\n",
      "       'well_irrigation_source_2_percentage',\n",
      "       'well_irrigation_type_1.0_percentage',\n",
      "       'well_irrigation_type_3.0_percentage', 'sprinklers_count',\n",
      "       'sprinklers_count_kw'],\n",
      "      dtype='object')\n",
      "\n",
      "Tuning RandomForest...\n",
      "\n",
      "Evaluation metrics for RandomForest (after tuning):\n",
      "MAE: 121.69\n",
      "RMSE: 184.76\n",
      "R2 Score: 0.41\n",
      "\n",
      "Tuning GradientBoosting...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 659, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nGradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, param_distributions\u001b[38;5;241m=\u001b[39mparam_grids[name],\n\u001b[1;32m     94\u001b[0m                                    n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     95\u001b[0m                                    random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Evaluate the best model from the random search\u001b[39;00m\n\u001b[1;32m     99\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 659, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nGradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "# Load the data\n",
    "df = df_integrated.copy()\n",
    "\n",
    "# Separate HASAR features from visits data\n",
    "# hasar_columns = [\n",
    "#     'farm_id', 'property_area', 'property_main_type', 'activity_count', \n",
    "#     'unique_crop_types_count', 'total_area_hectares', 'productive_trees_count', \n",
    "#     'protected_house_count', 'plantations_count'\n",
    "# ] + [col for col in df.columns if col.startswith(('activity_status_', 'farm_type_', \n",
    "#     'main_crop_type_', 'irrigation_source_', 'irrigation_type_', 'farming_season_', \n",
    "#     'protected_house_type_', 'plantations_type_', 'well_'))]\n",
    "\n",
    "\n",
    "df_hasar = df_integrated.drop(columns=['total_electrical_load_kw'])\n",
    "df_visits = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Handle missing values in HASAR data\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# df_hasar_imputed = pd.DataFrame(imputer.fit_transform(df_hasar), columns=df_hasar.columns)\n",
    "df_hasar_imputed = df_hasar.copy()\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = df_hasar_imputed.select_dtypes(include=[np.number]).columns\n",
    "df_hasar_imputed[numerical_features] = scaler.fit_transform(df_hasar_imputed[numerical_features])\n",
    "\n",
    "# Feature selection\n",
    "features = [col for col in df_hasar_imputed.columns if col not in ['farm_id']]\n",
    "selector = SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42), threshold='median')\n",
    "selector = selector.fit(df_hasar_imputed[features], df_visits['total_electrical_load_kw'])\n",
    "selected_features = df_hasar_imputed[features].columns[selector.get_support()]\n",
    "print(selected_features)\n",
    "# Prepare data for modeling\n",
    "X = df_hasar_imputed[selected_features]\n",
    "y = df_visits['total_electrical_load_kw']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.1, 0.2, 0.3],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV for each model\n",
    "best_model = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grids[name],\n",
    "                                       n_iter=20, cv=5, scoring='neg_mean_squared_error',\n",
    "                                       random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the best model from the random search\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred, f\"{name} (after tuning)\")\n",
    "    \n",
    "    # Update the best model if this one performed better\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = random_search.best_estimator_\n",
    "\n",
    "# Use the best model to make final predictions\n",
    "df_hasar_imputed['estimated_total_electrical_load_kw'] = best_model.predict(df_hasar_imputed[selected_features])\n",
    "\n",
    "# Merge predictions with actual values\n",
    "results = pd.merge(df_hasar_imputed[['farm_id', 'estimated_total_electrical_load_kw']], \n",
    "                   df_visits, on='farm_id', how='left')\n",
    "\n",
    "# Print results\n",
    "print(\"\\nSummary statistics of actual vs estimated total electrical load:\")\n",
    "print(results[['total_electrical_load_kw', 'estimated_total_electrical_load_kw']].describe())\n",
    "\n",
    "# Calculate final evaluation metrics\n",
    "final_predictions = results.dropna()\n",
    "evaluate_model(final_predictions['total_electrical_load_kw'], \n",
    "               final_predictions['estimated_total_electrical_load_kw'], \n",
    "               \"Final Model\")\n",
    "\n",
    "# Save the results\n",
    "results.to_csv('hasar_only_farm_consumption_estimates.csv', index=False)\n",
    "\n",
    "# Print feature importances\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = pd.DataFrame({'feature': selected_features, \n",
    "                                'importance': best_model.feature_importances_})\n",
    "    importances = importances.sort_values('importance', ascending=False)\n",
    "    print(\"\\nTop 10 most important features:\")\n",
    "    print(importances.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing cross-validation on the best model:\n",
      "\n",
      "Cross-Validation Results (mean Â± std):\n",
      "R2 Score: 0.328 Â± 0.025\n",
      "RMSE: 202.500 Â± 7.272\n",
      "MAE: 128.781 Â± 1.766\n",
      "\n",
      "Evaluating the model on the test set:\n",
      "\n",
      "Evaluation metrics for Best Ensemble Model (Test Set):\n",
      "MAE: 127.84\n",
      "RMSE: 195.93\n",
      "R2 Score: 0.34\n",
      "\n",
      "Summary statistics of actual vs estimated total electrical load:\n",
      "        actual_load  estimated_load\n",
      "count  10871.000000    10871.000000\n",
      "mean     350.052908      351.704628\n",
      "std      247.612605      138.376601\n",
      "min        7.460000      118.998257\n",
      "25%      236.500000      277.316278\n",
      "50%      323.400000      326.683116\n",
      "75%      398.000000      388.422214\n",
      "max     4291.500000     3069.514947\n",
      "\n",
      "Final evaluation metrics on the entire dataset:\n",
      "\n",
      "Evaluation metrics for Final Ensemble Model (Full Dataset):\n",
      "MAE: 105.70\n",
      "RMSE: 165.88\n",
      "R2 Score: 0.55\n",
      "\n",
      "Feature importance based on SHAP values:\n",
      "                    feature   importance\n",
      "1       total_area_hectares  1014.171143\n",
      "10               well_count    86.085157\n",
      "4             property_area    44.847068\n",
      "14        area_per_activity    36.034677\n",
      "0     irrigation_source_2.0    24.382939\n",
      "8       main_crop_type_15.0    17.574674\n",
      "13             well_density     5.276730\n",
      "2   unique_crop_types_count     4.164558\n",
      "11        trees_per_hectare     2.261151\n",
      "5    productive_trees_count     1.980502\n",
      "12     irrigation_intensity     1.205184\n",
      "3       irrigation_type_2.0     0.551115\n",
      "7            activity_count     0.087075\n",
      "6        main_crop_type_6.0     0.000000\n",
      "9       irrigation_type_4.0     0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "class NonNegativeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.base_estimator.predict(X)\n",
    "        return np.maximum(predictions, 0)\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = df_integrated.copy()\n",
    "    \n",
    "    # Top 10 important features based on SHAP values\n",
    "    important_features = [\n",
    "        'irrigation_source_2.0', 'total_area_hectares', 'unique_crop_types_count',\n",
    "        'irrigation_type_2.0', 'property_area', 'productive_trees_count',\n",
    "        'main_crop_type_6.0', 'activity_count', 'main_crop_type_15.0',\n",
    "        'irrigation_type_4.0', 'well_count'\n",
    "    ]\n",
    "    \n",
    "    # Add 'farm_id' for joining purposes\n",
    "    columns_to_keep = ['farm_id'] + important_features\n",
    "    \n",
    "    df_hasar = df[columns_to_keep]\n",
    "    df_target = df[['farm_id', 'total_electrical_load_kw']]\n",
    "    \n",
    "    return df_hasar, df_target\n",
    "\n",
    "def engineer_features(df):\n",
    "    df['trees_per_hectare'] = df['productive_trees_count'] / df['total_area_hectares']\n",
    "    df['irrigation_intensity'] = df['irrigation_type_2.0'] * df['total_area_hectares']\n",
    "    df['well_density'] = df['well_count'] / df['total_area_hectares']\n",
    "    df['area_per_activity'] = df['total_area_hectares'] / df['activity_count']\n",
    "    return df\n",
    "\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', QuantileTransformer(output_distribution='normal'))\n",
    "            ]), numeric_features),\n",
    "            ('cat', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), categorical_features)\n",
    "        ])\n",
    "    return preprocessor\n",
    "\n",
    "def create_ensemble_model():\n",
    "    gb_model = NonNegativeRegressor(GradientBoostingRegressor(random_state=42))\n",
    "    rf_model = NonNegativeRegressor(RandomForestRegressor(random_state=42))\n",
    "\n",
    "    ensemble = VotingRegressor([\n",
    "        ('gb', gb_model),\n",
    "        ('rf', rf_model)\n",
    "    ])\n",
    "    return ensemble\n",
    "\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "def perform_cross_validation(model, X, y, cv=5):\n",
    "    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "    rmse_scores = np.sqrt(-cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error'))\n",
    "    mae_scores = -cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    print(f\"\\nCross-Validation Results (mean Â± std):\")\n",
    "    print(f\"R2 Score: {r2_scores.mean():.3f} Â± {r2_scores.std():.3f}\")\n",
    "    print(f\"RMSE: {rmse_scores.mean():.3f} Â± {rmse_scores.std():.3f}\")\n",
    "    print(f\"MAE: {mae_scores.mean():.3f} Â± {mae_scores.std():.3f}\")\n",
    "\n",
    "def compute_shap_values(model, X):\n",
    "    explainer = shap.TreeExplainer(model.estimators_[0].base_estimator)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    feature_names = X.columns\n",
    "    shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "    importance_df = pd.DataFrame(list(zip(feature_names, shap_sum)), columns=['feature', 'importance'])\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature importance based on SHAP values:\")\n",
    "    print(importance_df)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "def save_pipeline(pipeline, feature_names, file_path):\n",
    "    pipeline_data = {\n",
    "        'pipeline': pipeline,\n",
    "        'feature_names': feature_names\n",
    "    }\n",
    "    joblib.dump(pipeline_data, file_path)\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    df_hasar, df_target = load_and_preprocess_data('df_integrated.csv')\n",
    "    df_hasar = engineer_features(df_hasar)\n",
    "\n",
    "    # Prepare data for modeling\n",
    "    X = df_hasar.drop('farm_id', axis=1)\n",
    "    y = df_target['total_electrical_load_kw']\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create preprocessor and model\n",
    "    preprocessor = create_preprocessor(X)\n",
    "    ensemble = create_ensemble_model()\n",
    "\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', ensemble)\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for RandomizedSearchCV\n",
    "    param_grid = {\n",
    "        'model__gb__base_estimator__n_estimators': [100, 200, 300],\n",
    "        'model__gb__base_estimator__max_depth': [3, 4, 5],\n",
    "        'model__gb__base_estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__rf__base_estimator__n_estimators': [100, 200, 300],\n",
    "        'model__rf__base_estimator__max_depth': [10, 20, 30, None],\n",
    "        'model__rf__base_estimator__min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,\n",
    "                                       n_iter=20, cv=5, scoring='neg_mean_squared_error',\n",
    "                                       random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_pipeline = random_search.best_estimator_\n",
    "\n",
    "    # Perform cross-validation\n",
    "    print(\"\\nPerforming cross-validation on the best model:\")\n",
    "    perform_cross_validation(best_pipeline, X, y)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = best_pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    print(\"\\nEvaluating the model on the test set:\")\n",
    "    evaluate_model(y_test, y_pred_test, \"Best Ensemble Model (Test Set)\")\n",
    "\n",
    "    # Make predictions on the entire dataset\n",
    "    y_pred_all = best_pipeline.predict(X)\n",
    "\n",
    "    # Merge predictions with actual values\n",
    "    results = pd.DataFrame({\n",
    "        'farm_id': df_hasar['farm_id'],\n",
    "        'actual_load': df_target['total_electrical_load_kw'],\n",
    "        'estimated_load': y_pred_all\n",
    "    })\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary statistics of actual vs estimated total electrical load:\")\n",
    "    print(results[['actual_load', 'estimated_load']].describe())\n",
    "\n",
    "    # Calculate final evaluation metrics\n",
    "    print(\"\\nFinal evaluation metrics on the entire dataset:\")\n",
    "    evaluate_model(results['actual_load'], results['estimated_load'], \"Final Ensemble Model (Full Dataset)\")\n",
    "\n",
    "    # Compute SHAP values\n",
    "    compute_shap_values(best_pipeline.named_steps['model'], X)\n",
    "\n",
    "    # Save the results\n",
    "    results.to_csv('ensemble_hasar_farm_consumption_estimates.csv', index=False)\n",
    "\n",
    "    # Save the pipeline and feature names\n",
    "    save_pipeline(best_pipeline, X.columns.tolist(), 'hasar_farm_pipeline.joblib')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'trees_per_hectare' not found in the new data.\n",
      "Feature 'irrigation_intensity' not found in the new data.\n",
      "Feature 'well_density' not found in the new data.\n",
      "Feature 'area_per_activity' not found in the new data.\n",
      "   irrigation_source_2.0  total_area_hectares  unique_crop_types_count  \\\n",
      "3                    4.0            86.170176                      3.0   \n",
      "\n",
      "   irrigation_type_2.0  property_area  productive_trees_count  \\\n",
      "3                  0.0   1.171881e+06                     0.0   \n",
      "\n",
      "   main_crop_type_6.0  activity_count  main_crop_type_15.0  \\\n",
      "3                 0.0             4.0                  0.0   \n",
      "\n",
      "   irrigation_type_4.0  well_count  trees_per_hectare  irrigation_intensity  \\\n",
      "3                  0.0         2.0                  0                     0   \n",
      "\n",
      "   well_density  area_per_activity  \n",
      "3             0                  0  \n",
      "Predictions for new data:\n",
      "Farm 1: Estimated electrical load: 446.63 kW\n"
     ]
    }
   ],
   "source": [
    "# Inference Code Very Important\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "def load_pipeline(file_path):\n",
    "    return joblib.load(file_path)\n",
    "\n",
    "def inference(pipeline_data, new_data):\n",
    "    pipeline = pipeline_data['pipeline']\n",
    "    feature_names = pipeline_data['feature_names']\n",
    "\n",
    "    # Ensure new_data has all the required features\n",
    "    for feature in feature_names:\n",
    "        \n",
    "        if feature not in new_data.columns:\n",
    "            print(f\"Feature '{feature}' not found in the new data.\")\n",
    "            \n",
    "            new_data[feature] = 0  # or any appropriate default value\n",
    "\n",
    "    # Select only the features used during training\n",
    "    new_data = new_data[feature_names]\n",
    "    print(new_data)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = pipeline.predict(new_data)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def main():\n",
    "    # Load the saved pipeline\n",
    "    pipeline_data = load_pipeline('hasar_farm_pipeline.joblib')\n",
    "\n",
    "    # Create some sample new data (adjust this according to your feature set)\n",
    "    new_data = df_integrated.iloc[[3],:]\n",
    "    \n",
    "\n",
    "    # Make predictions on new data\n",
    "    predictions = inference(pipeline_data, new_data)\n",
    "\n",
    "    print(\"Predictions for new data:\")\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"Farm {i+1}: Estimated electrical load: {pred:.2f} kW\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics for Random Forest with Proper Preprocessing:\n",
      "MAE: 123.52\n",
      "RMSE: 190.42\n",
      "R2 Score: 0.37\n",
      "Cross-validated R2 scores: [0.34660542 0.31796785 0.32114235 0.33086074 0.34876533]\n",
      "Mean R2 score: 0.33306834002160624\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load and prepare your features (HASAR data only)\n",
    "df_features = df_integrated.copy().drop(columns=['total_electrical_load_kw'])  # Now, df_integrated contains only HASAR data\n",
    "\n",
    "# Load your target variable\n",
    "df_target = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Merge features and target on 'farm_id'\n",
    "df_merged = df_integrated.copy()\n",
    "\n",
    "# Separate features and target\n",
    "X = df_merged.drop(columns=['farm_id', 'total_electrical_load_kw'])\n",
    "y = df_merged['total_electrical_load_kw']\n",
    "\n",
    "# Ensure that 'total_electrical_load_kw' is not present in X\n",
    "assert 'total_electrical_load_kw' not in X.columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42))),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Set up hyperparameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__n_estimators': [100, 200],\n",
    "    'feature_selection__estimator__max_depth': [None, 10, 20],\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,\n",
    "                                   n_iter=10, cv=5, scoring='neg_mean_squared_error',\n",
    "                                   random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "best_pipeline = random_search.best_estimator_\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Random Forest with Proper Preprocessing\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_pipeline, X, y, cv=cv, scoring='r2')\n",
    "print(f\"Cross-validated R2 scores: {cv_scores}\")\n",
    "print(f\"Mean R2 score: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics for Random Forest with Log-Transformed Target:\n",
      "MAE: 118.09\n",
      "RMSE: 199.03\n",
      "R2 Score: 0.3150\n",
      "\n",
      "Evaluation metrics for XGBoost with Log-Transformed Target:\n",
      "MAE: 117.31\n",
      "RMSE: 196.40\n",
      "R2 Score: 0.3330\n",
      "\n",
      "Evaluation metrics for Ensemble Model (Average of RF and XGBoost):\n",
      "MAE: 117.34\n",
      "RMSE: 197.28\n",
      "R2 Score: 0.3270\n",
      "\n",
      "Cross-validated MAE scores: [np.float64(117.37932336394925), np.float64(119.30180086019266), np.float64(120.49022500821012), np.float64(122.07405813160135), np.float64(129.14229762748707)]\n",
      "Mean MAE score: 121.68\n",
      "Cross-validated RMSE scores: [np.float64(197.00197883254577), np.float64(207.27032308142196), np.float64(195.0389118708773), np.float64(203.89322137584), np.float64(234.52711865801876)]\n",
      "Mean RMSE score: 207.55\n",
      "Cross-validated R2 scores: [0.3288486930841722, 0.3078377217987891, 0.308770122868294, 0.2999795909984345, 0.23664271061289877]\n",
      "Mean R2 score: 0.2964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load and prepare your features (assuming df_integrated contains the features)\n",
    "df_features = df_integrated.copy().drop(columns=['total_electrical_load_kw'])  # Now, df_integrated contains only HASAR data\n",
    "\n",
    "# Load your target variable\n",
    "df_target = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Merge features and target on 'farm_id'\n",
    "df_merged = df_integrated.copy()\n",
    "\n",
    "# List of new features to be created and the required columns for each\n",
    "new_features = {\n",
    "    'trees_per_hectare': ['productive_trees_count', 'total_area_hectares'],\n",
    "    'irrigation_intensity': ['irrigation_type_2.0', 'total_area_hectares'],\n",
    "    'well_density': ['well_count', 'total_area_hectares'],\n",
    "    'area_per_activity': ['total_area_hectares', 'activity_count']\n",
    "}\n",
    "\n",
    "# Check if required columns exist and create features if they do\n",
    "for feature_name, required_cols in new_features.items():\n",
    "    missing_cols = [col for col in required_cols if col not in df_merged.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Cannot create feature '{feature_name}' because the following columns are missing: {missing_cols}\")\n",
    "        # Assign default value or decide how to handle missing columns\n",
    "        df_merged[feature_name] = 0\n",
    "    else:\n",
    "        # Handle potential division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            if feature_name == 'trees_per_hectare':\n",
    "                df_merged[feature_name] = df_merged['productive_trees_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'irrigation_intensity':\n",
    "                df_merged[feature_name] = df_merged['irrigation_type_2.0'] * df_merged['total_area_hectares']\n",
    "            elif feature_name == 'well_density':\n",
    "                df_merged[feature_name] = df_merged['well_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'area_per_activity':\n",
    "                df_merged[feature_name] = df_merged['total_area_hectares'] / df_merged['activity_count']\n",
    "\n",
    "# Replace infinite and NaN values resulting from division by zero\n",
    "df_merged.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_merged.drop(columns=['farm_id', 'total_electrical_load_kw'])\n",
    "y = df_merged['total_electrical_load_kw']\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "y_log = np.log1p(y)  # Use log1p to handle zero values\n",
    "\n",
    "# Ensure that 'total_electrical_load_kw' is not present in X\n",
    "assert 'total_electrical_load_kw' not in X.columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipelines\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "])\n",
    "\n",
    "# Set up hyperparameter grids\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__subsample': [0.6, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    pipeline_rf,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_rf.fit(X_train, y_train_log)\n",
    "\n",
    "# Perform RandomizedSearchCV for XGBoost\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_distributions=param_grid_xgb,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_xgb.fit(X_train, y_train_log)\n",
    "\n",
    "# Best models\n",
    "best_pipeline_rf = random_search_rf.best_estimator_\n",
    "best_pipeline_xgb = random_search_xgb.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log_rf = best_pipeline_rf.predict(X_test)\n",
    "y_pred_rf = np.expm1(y_pred_log_rf)\n",
    "\n",
    "y_pred_log_xgb = best_pipeline_xgb.predict(X_test)\n",
    "y_pred_xgb = np.expm1(y_pred_log_xgb)\n",
    "\n",
    "# Inverse transform the test target variable\n",
    "y_test_actual = np.expm1(y_test_log)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "evaluate_model(y_test_actual, y_pred_rf, \"Random Forest with Log-Transformed Target\")\n",
    "\n",
    "# Evaluate XGBoost\n",
    "evaluate_model(y_test_actual, y_pred_xgb, \"XGBoost with Log-Transformed Target\")\n",
    "\n",
    "# Ensemble predictions\n",
    "y_pred_ensemble = (y_pred_rf + y_pred_xgb) / 2\n",
    "\n",
    "# Evaluate Ensemble Model\n",
    "evaluate_model(y_test_actual, y_pred_ensemble, \"Ensemble Model (Average of RF and XGBoost)\")\n",
    "\n",
    "# Cross-validation for Ensemble Model\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_cv_train, X_cv_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_cv_train_log, y_cv_test_log = y_log.iloc[train_index], y_log.iloc[test_index]\n",
    "    y_cv_test_actual = np.expm1(y_cv_test_log)\n",
    "    \n",
    "    # Fit Random Forest\n",
    "    best_pipeline_rf.fit(X_cv_train, y_cv_train_log)\n",
    "    y_pred_log_rf_cv = best_pipeline_rf.predict(X_cv_test)\n",
    "    y_pred_rf_cv = np.expm1(y_pred_log_rf_cv)\n",
    "    \n",
    "    # Fit XGBoost\n",
    "    best_pipeline_xgb.fit(X_cv_train, y_cv_train_log)\n",
    "    y_pred_log_xgb_cv = best_pipeline_xgb.predict(X_cv_test)\n",
    "    y_pred_xgb_cv = np.expm1(y_pred_log_xgb_cv)\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    y_pred_ensemble_cv = (y_pred_rf_cv + y_pred_xgb_cv) / 2\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_cv_test_actual, y_pred_ensemble_cv)\n",
    "    rmse = np.sqrt(mean_squared_error(y_cv_test_actual, y_pred_ensemble_cv))\n",
    "    r2 = r2_score(y_cv_test_actual, y_pred_ensemble_cv)\n",
    "    \n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Display cross-validated metrics\n",
    "print(f\"\\nCross-validated MAE scores: {mae_scores}\")\n",
    "print(f\"Mean MAE score: {np.mean(mae_scores):.2f}\")\n",
    "\n",
    "print(f\"Cross-validated RMSE scores: {rmse_scores}\")\n",
    "print(f\"Mean RMSE score: {np.mean(rmse_scores):.2f}\")\n",
    "\n",
    "print(f\"Cross-validated R2 scores: {r2_scores}\")\n",
    "print(f\"Mean R2 score: {np.mean(r2_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics for Random Forest with New Features and Log-Transformed Target:\n",
      "MAE: 117.78\n",
      "RMSE: 198.71\n",
      "R2 Score: 0.32\n",
      "Cross-validated RMSE scores: [0.51168469 0.50378386 0.53795992 0.52850403 0.53671985]\n",
      "Mean RMSE score: 0.5237304711930477\n",
      "Cross-validated R2 scores: [0.38623499 0.40019886 0.33590525 0.34261801 0.3664779 ]\n",
      "Mean R2 score: 0.36628700290990646\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load and prepare your features (assuming df_integrated contains the features)\n",
    "df_features = df_integrated.copy().drop(columns=['total_electrical_load_kw'])  # Now, df_integrated contains only HASAR data\n",
    "\n",
    "# Load your target variable\n",
    "df_target = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Merge features and target on 'farm_id'\n",
    "df_merged = df_integrated.copy()\n",
    "\n",
    "# List of new features to be created and the required columns for each\n",
    "new_features = {\n",
    "    'trees_per_hectare': ['productive_trees_count', 'total_area_hectares'],\n",
    "    'irrigation_intensity': ['irrigation_type_2.0', 'total_area_hectares'],\n",
    "    'well_density': ['well_count', 'total_area_hectares'],\n",
    "    'area_per_activity': ['total_area_hectares', 'activity_count']\n",
    "}\n",
    "\n",
    "# Check if required columns exist and create features if they do\n",
    "for feature_name, required_cols in new_features.items():\n",
    "    missing_cols = [col for col in required_cols if col not in df_merged.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Cannot create feature '{feature_name}' because the following columns are missing: {missing_cols}\")\n",
    "        # Assign default value or decide how to handle missing columns\n",
    "        df_merged[feature_name] = 0\n",
    "    else:\n",
    "        # Handle potential division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            if feature_name == 'trees_per_hectare':\n",
    "                df_merged[feature_name] = df_merged['productive_trees_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'irrigation_intensity':\n",
    "                df_merged[feature_name] = df_merged['irrigation_type_2.0'] * df_merged['total_area_hectares']\n",
    "            elif feature_name == 'well_density':\n",
    "                df_merged[feature_name] = df_merged['well_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'area_per_activity':\n",
    "                df_merged[feature_name] = df_merged['total_area_hectares'] / df_merged['activity_count']\n",
    "\n",
    "# Replace infinite and NaN values resulting from division by zero\n",
    "df_merged.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_merged.drop(columns=['farm_id', 'total_electrical_load_kw'])\n",
    "y = df_merged['total_electrical_load_kw']\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "y_log = np.log1p(y)  # Use log1p to handle zero values\n",
    "\n",
    "# Ensure that 'total_electrical_load_kw' is not present in X\n",
    "assert 'total_electrical_load_kw' not in X.columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Set up hyperparameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Evaluate the model\n",
    "best_rf_pipeline = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = best_rf_pipeline.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred = np.expm1(y_pred_log)  # Use expm1 to reverse log1p\n",
    "\n",
    "# Inverse transform the test target variable\n",
    "y_test_actual = np.expm1(y_test_log)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "evaluate_model(y_test_actual, y_pred, \"Random Forest with New Features and Log-Transformed Target\")\n",
    "\n",
    "# Perform cross-validation on the full dataset\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_rf_pipeline, X, y_log, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Convert negative MSE scores to positive RMSE scores\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "print(f\"Cross-validated RMSE scores: {cv_rmse_scores}\")\n",
    "print(f\"Mean RMSE score: {cv_rmse_scores.mean()}\")\n",
    "\n",
    "# Compute R2 scores during cross-validation\n",
    "cv_r2_scores = cross_val_score(best_rf_pipeline, X, y_log, cv=cv, scoring='r2', n_jobs=-1)\n",
    "print(f\"Cross-validated R2 scores: {cv_r2_scores}\")\n",
    "print(f\"Mean R2 score: {cv_r2_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics for Random Forest with Log-Transformed Target:\n",
      "MAE: 117.78\n",
      "RMSE: 198.71\n",
      "R2 Score: 0.3172\n",
      "\n",
      "Evaluation metrics for XGBoost with Log-Transformed Target:\n",
      "MAE: 117.57\n",
      "RMSE: 196.27\n",
      "R2 Score: 0.3338\n",
      "\n",
      "Evaluation metrics for Stacking Regressor (Meta-Learner):\n",
      "MAE: 116.80\n",
      "RMSE: 194.23\n",
      "R2 Score: 0.3476\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor: [0.39033692 0.40524829 0.34535852 0.35386417 0.37744808]\n",
      "Mean R2 score: 0.3745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Load and prepare your features (assuming df_integrated contains the features)\n",
    "df_features = df_integrated.copy().drop(columns=['total_electrical_load_kw'])  # Now, df_integrated contains only HASAR data\n",
    "\n",
    "# Load your target variable\n",
    "df_target = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Merge features and target on 'farm_id'\n",
    "df_merged = df_integrated.copy()\n",
    "\n",
    "# List of new features to be created and the required columns for each\n",
    "new_features = {\n",
    "    'trees_per_hectare': ['productive_trees_count', 'total_area_hectares'],\n",
    "    'irrigation_intensity': ['irrigation_type_2.0', 'total_area_hectares'],\n",
    "    'well_density': ['well_count', 'total_area_hectares'],\n",
    "    'area_per_activity': ['total_area_hectares', 'activity_count']\n",
    "}\n",
    "\n",
    "# Check if required columns exist and create features if they do\n",
    "for feature_name, required_cols in new_features.items():\n",
    "    missing_cols = [col for col in required_cols if col not in df_merged.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Cannot create feature '{feature_name}' because the following columns are missing: {missing_cols}\")\n",
    "        # Assign default value or decide how to handle missing columns\n",
    "        df_merged[feature_name] = 0\n",
    "    else:\n",
    "        # Handle potential division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            if feature_name == 'trees_per_hectare':\n",
    "                df_merged[feature_name] = df_merged['productive_trees_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'irrigation_intensity':\n",
    "                df_merged[feature_name] = df_merged['irrigation_type_2.0'] * df_merged['total_area_hectares']\n",
    "            elif feature_name == 'well_density':\n",
    "                # Ensure well_id is a count, not an identifier\n",
    "                if 'well_count' in df_merged.columns:\n",
    "                    df_merged[feature_name] = df_merged['well_count'] / df_merged['total_area_hectares']\n",
    "                else:\n",
    "                    print(f\"Cannot create feature '{feature_name}' because 'well_id' column is missing.\")\n",
    "                    df_merged[feature_name] = 0\n",
    "            elif feature_name == 'area_per_activity':\n",
    "                df_merged[feature_name] = df_merged['total_area_hectares'] / df_merged['activity_count']\n",
    "\n",
    "# Replace infinite and NaN values resulting from division by zero\n",
    "df_merged.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_merged.drop(columns=['farm_id', 'total_electrical_load_kw'])\n",
    "y = df_merged['total_electrical_load_kw']\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "y_log = np.log1p(y)  # Use log1p to handle zero values\n",
    "\n",
    "# Ensure that 'total_electrical_load_kw' is not present in X\n",
    "assert 'total_electrical_load_kw' not in X.columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the base learners\n",
    "# Random Forest pipeline\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# XGBoost pipeline\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.7, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    pipeline_rf,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_rf.fit(X_train, y_train_log)\n",
    "\n",
    "# Perform RandomizedSearchCV for XGBoost\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_distributions=param_grid_xgb,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_xgb.fit(X_train, y_train_log)\n",
    "\n",
    "# Best estimators\n",
    "best_pipeline_rf = random_search_rf.best_estimator_\n",
    "best_pipeline_xgb = random_search_xgb.best_estimator_\n",
    "\n",
    "# Define the stacking regressor\n",
    "estimators = [\n",
    "    ('rf', best_pipeline_rf),\n",
    "    ('xgb', best_pipeline_xgb)\n",
    "]\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LinearRegression(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the stacking regressor\n",
    "stacking_regressor.fit(X_train, y_train_log)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_stack = stacking_regressor.predict(X_test)\n",
    "y_pred_stack = np.expm1(y_pred_log_stack)\n",
    "\n",
    "# Inverse transform the test target variable\n",
    "y_test_actual = np.expm1(y_test_log)\n",
    "\n",
    "# Evaluate the stacking regressor\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Evaluate individual models\n",
    "# Random Forest\n",
    "y_pred_log_rf = best_pipeline_rf.predict(X_test)\n",
    "y_pred_rf = np.expm1(y_pred_log_rf)\n",
    "evaluate_model(y_test_actual, y_pred_rf, \"Random Forest with Log-Transformed Target\")\n",
    "\n",
    "# XGBoost\n",
    "y_pred_log_xgb = best_pipeline_xgb.predict(X_test)\n",
    "y_pred_xgb = np.expm1(y_pred_log_xgb)\n",
    "evaluate_model(y_test_actual, y_pred_xgb, \"XGBoost with Log-Transformed Target\")\n",
    "\n",
    "# Evaluate stacking regressor\n",
    "evaluate_model(y_test_actual, y_pred_stack, \"Stacking Regressor (Meta-Learner)\")\n",
    "\n",
    "# Cross-validation for stacking regressor\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(stacking_regressor, X, y_log, cv=cv, scoring='r2', n_jobs=-1)\n",
    "print(f\"\\nCross-validated R2 scores for Stacking Regressor: {cv_scores}\")\n",
    "print(f\"Mean R2 score: {cv_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n",
      "Tuning XGBoost...\n",
      "Tuning LightGBM...\n",
      "Tuning CatBoost...\n",
      "Tuning MLPRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Stacking Regressor with Ridge Meta-Learner...\n",
      "Tuning Stacking Regressor with Lasso Meta-Learner...\n",
      "Fitting the original Stacking Regressor with LinearRegression...\n",
      "\n",
      "Evaluation metrics for Random Forest with Log-Transformed Target:\n",
      "MAE: 98.86\n",
      "RMSE: 132.66\n",
      "R2 Score: 0.2865\n",
      "\n",
      "Evaluation metrics for XGBoost with Log-Transformed Target:\n",
      "MAE: 97.07\n",
      "RMSE: 130.83\n",
      "R2 Score: 0.3060\n",
      "\n",
      "Evaluation metrics for LightGBM with Log-Transformed Target:\n",
      "MAE: 98.91\n",
      "RMSE: 132.00\n",
      "R2 Score: 0.2936\n",
      "\n",
      "Evaluation metrics for CatBoost with Log-Transformed Target:\n",
      "MAE: 96.19\n",
      "RMSE: 129.95\n",
      "R2 Score: 0.3153\n",
      "\n",
      "Evaluation metrics for MLPRegressor with Log-Transformed Target:\n",
      "MAE: 101.14\n",
      "RMSE: 134.47\n",
      "R2 Score: 0.2669\n",
      "\n",
      "Evaluation metrics for Stacking Regressor with LinearRegression Meta-Learner:\n",
      "MAE: 96.56\n",
      "RMSE: 130.13\n",
      "R2 Score: 0.3134\n",
      "\n",
      "Evaluation metrics for Stacking Regressor with Ridge Meta-Learner:\n",
      "MAE: 96.93\n",
      "RMSE: 130.32\n",
      "R2 Score: 0.3114\n",
      "\n",
      "Evaluation metrics for Stacking Regressor with Lasso Meta-Learner:\n",
      "MAE: 96.59\n",
      "RMSE: 130.14\n",
      "R2 Score: 0.3133\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor with LinearRegression Meta-Learner: [0.37332306 0.3904247  0.32319876 0.33443562 0.36374113]\n",
      "Mean R2 score: 0.3570\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor with Ridge Meta-Learner: [0.37387668 0.38996937 0.32336532 0.33558086 0.36687145]\n",
      "Mean R2 score: 0.3579\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor with Lasso Meta-Learner: [0.37311147 0.39079672 0.32275963 0.33474495 0.36354371]\n",
      "Mean R2 score: 0.3570\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Importing Alternative Algorithms\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ----------------------- Custom Transformer for Outlier Capping -----------------------\n",
    "\n",
    "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables=None, factor=1.5):\n",
    "        \"\"\"\n",
    "        Cap the outliers in specified variables using the IQR method.\n",
    "\n",
    "        Parameters:\n",
    "        - variables: list of column names to apply capping.\n",
    "        - factor: multiplier for the IQR to define the cap.\n",
    "        \"\"\"\n",
    "        self.variables = variables\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.cap_dict_ = {}\n",
    "        for var in self.variables:\n",
    "            Q1 = X[var].quantile(0.25)\n",
    "            Q3 = X[var].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_cap = Q1 - self.factor * IQR\n",
    "            upper_cap = Q3 + self.factor * IQR\n",
    "            self.cap_dict_[var] = (lower_cap, upper_cap)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_capped = X.copy()\n",
    "        for var in self.variables:\n",
    "            lower_cap, upper_cap = self.cap_dict_[var]\n",
    "            X_capped[var] = np.where(\n",
    "                X_capped[var] < lower_cap, lower_cap,\n",
    "                np.where(X_capped[var] > upper_cap, upper_cap, X_capped[var])\n",
    "            )\n",
    "        return X_capped\n",
    "\n",
    "# ----------------------- Data Preparation -----------------------\n",
    "\n",
    "# Load and prepare your features (assuming df_integrated contains the features)\n",
    "df_features = df_integrated.copy().drop(columns=['total_electrical_load_kw'])  # Now, df_integrated contains only HASAR data\n",
    "\n",
    "# Load your target variable\n",
    "df_target = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Merge features and target on 'farm_id'\n",
    "df_merged = df_integrated.copy()\n",
    "\n",
    "# List of new features to be created and the required columns for each\n",
    "new_features = {\n",
    "    'trees_per_hectare': ['productive_trees_count', 'total_area_hectares'],\n",
    "    'irrigation_intensity': ['irrigation_type_2.0', 'total_area_hectares'],\n",
    "    'well_density': ['well_count', 'total_area_hectares'],\n",
    "    'area_per_activity': ['total_area_hectares', 'activity_count']\n",
    "}\n",
    "\n",
    "# Check if required columns exist and create features if they do\n",
    "for feature_name, required_cols in new_features.items():\n",
    "    missing_cols = [col for col in required_cols if col not in df_merged.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Cannot create feature '{feature_name}' because the following columns are missing: {missing_cols}\")\n",
    "        # Assign default value or decide how to handle missing columns\n",
    "        df_merged[feature_name] = 0\n",
    "    else:\n",
    "        # Handle potential division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            if feature_name == 'trees_per_hectare':\n",
    "                df_merged[feature_name] = df_merged['productive_trees_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'irrigation_intensity':\n",
    "                df_merged[feature_name] = df_merged['irrigation_type_2.0'] * df_merged['total_area_hectares']\n",
    "            elif feature_name == 'well_density':\n",
    "                # Ensure well_id is a count, not an identifier\n",
    "                if 'well_count' in df_merged.columns:\n",
    "                    df_merged[feature_name] = df_merged['well_count'] / df_merged['total_area_hectares']\n",
    "                else:\n",
    "                    print(f\"Cannot create feature '{feature_name}' because 'well_id' column is missing.\")\n",
    "                    df_merged[feature_name] = 0\n",
    "            elif feature_name == 'area_per_activity':\n",
    "                df_merged[feature_name] = df_merged['total_area_hectares'] / df_merged['activity_count']\n",
    "\n",
    "# Replace infinite and NaN values resulting from division by zero\n",
    "df_merged.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_merged.drop(columns=['farm_id', 'total_electrical_load_kw'])\n",
    "y = df_merged['total_electrical_load_kw']\n",
    "\n",
    "# ----------------------- Handle Outliers in the Target Variable -----------------------\n",
    "\n",
    "# Initialize OutlierCapper for the target variable\n",
    "target_capper = OutlierCapper(variables=['total_electrical_load_kw'], factor=1.5)\n",
    "y_capped = target_capper.fit_transform(X.assign(total_electrical_load_kw=y))['total_electrical_load_kw']\n",
    "\n",
    "# Apply log transformation\n",
    "y_log = np.log1p(y_capped)\n",
    "\n",
    "# Ensure that 'total_electrical_load_kw' is not present in X\n",
    "assert 'total_electrical_load_kw' not in X.columns\n",
    "\n",
    "# ----------------------- Split the Data -----------------------\n",
    "\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------- Preprocessing Pipelines -----------------------\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "variables_to_cap = numeric_features  # You can customize this list\n",
    "\n",
    "# Update the numeric transformer pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('outlier_capper', OutlierCapper(variables=variables_to_cap, factor=1.5)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# ----------------------- Define Base Learners Pipelines -----------------------\n",
    "\n",
    "# Random Forest pipeline\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# XGBoost pipeline\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "\n",
    "# LightGBM pipeline\n",
    "pipeline_lgbm = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LGBMRegressor(verbose=-1, random_state=42))\n",
    "])\n",
    "\n",
    "# CatBoost pipeline\n",
    "pipeline_cat = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', CatBoostRegressor(random_state=42, verbose=0))\n",
    "])\n",
    "\n",
    "# Neural Network pipeline\n",
    "pipeline_mlp = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', MLPRegressor(random_state=42, max_iter=500))\n",
    "])\n",
    "\n",
    "# ----------------------- Define Hyperparameter Grids -----------------------\n",
    "\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.7, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [5, 10, 15],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__num_leaves': [31, 50, 100],\n",
    "    'regressor__subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_grid_cat = {\n",
    "    'regressor__iterations': [500, 1000],\n",
    "    'regressor__depth': [4, 6, 8],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'regressor__hidden_layer_sizes': [(100,), (100, 50), (100, 100, 50)],\n",
    "    'regressor__activation': ['relu', 'tanh'],\n",
    "    'regressor__solver': ['adam', 'lbfgs'],\n",
    "    'regressor__alpha': [0.0001, 0.001, 0.01],\n",
    "    'regressor__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# ----------------------- Hyperparameter Tuning with RandomizedSearchCV -----------------------\n",
    "\n",
    "# Function to perform RandomizedSearchCV\n",
    "def randomized_search(pipeline, param_distributions, X, y, n_iter, cv, scoring, random_state=42):\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    return search\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV for each model\n",
    "print(\"Tuning Random Forest...\")\n",
    "random_search_rf = randomized_search(\n",
    "    pipeline_rf,\n",
    "    param_grid_rf,\n",
    "    X_train,\n",
    "    y_train_log,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'  # You can choose 'neg_root_mean_squared_error' or others\n",
    ")\n",
    "\n",
    "print(\"Tuning XGBoost...\")\n",
    "random_search_xgb = randomized_search(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    X_train,\n",
    "    y_train_log,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(\"Tuning LightGBM...\")\n",
    "random_search_lgbm = randomized_search(\n",
    "    pipeline_lgbm,\n",
    "    param_grid_lgbm,\n",
    "    X_train,\n",
    "    y_train_log,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(\"Tuning CatBoost...\")\n",
    "random_search_cat = randomized_search(\n",
    "    pipeline_cat,\n",
    "    param_grid_cat,\n",
    "    X_train,\n",
    "    y_train_log,\n",
    "    n_iter=5,  # CatBoost can be time-consuming; reduce iterations if necessary\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(\"Tuning MLPRegressor...\")\n",
    "random_search_mlp = randomized_search(\n",
    "    pipeline_mlp,\n",
    "    param_grid_mlp,\n",
    "    X_train,\n",
    "    y_train_log,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# ----------------------- Retrieve Best Estimators -----------------------\n",
    "\n",
    "best_pipeline_rf = random_search_rf.best_estimator_\n",
    "best_pipeline_xgb = random_search_xgb.best_estimator_\n",
    "best_pipeline_lgbm = random_search_lgbm.best_estimator_\n",
    "best_pipeline_cat = random_search_cat.best_estimator_\n",
    "best_pipeline_mlp = random_search_mlp.best_estimator_\n",
    "\n",
    "# ----------------------- Define the Enhanced Stacking Regressor -----------------------\n",
    "\n",
    "# Update estimators list to include all base learners\n",
    "estimators = [\n",
    "    ('rf', best_pipeline_rf),\n",
    "    ('xgb', best_pipeline_xgb),\n",
    "    ('lgbm', best_pipeline_lgbm),\n",
    "    ('cat', best_pipeline_cat),\n",
    "    ('mlp', best_pipeline_mlp)\n",
    "]\n",
    "\n",
    "# Original Stacking Regressor with LinearRegression as Meta-Learner\n",
    "stacking_regressor_lr = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LinearRegression(),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False  # Set to True if you want to include original features in the meta-learner\n",
    ")\n",
    "\n",
    "# ----------------------- Define and Tune Stacking Regressors with Ridge and Lasso Meta-Learners -----------------------\n",
    "\n",
    "# Define stacking regressors with Ridge and Lasso as meta-learners\n",
    "stacking_regressor_ridge = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(random_state=42),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "stacking_regressor_lasso = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Lasso(random_state=42),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# Define hyperparameter grids for meta-learners\n",
    "param_grid_meta_ridge = {\n",
    "    'final_estimator__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "param_grid_meta_lasso = {\n",
    "    'final_estimator__alpha': [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV for Stacking Regressor with Ridge Meta-Learner\n",
    "print(\"Tuning Stacking Regressor with Ridge Meta-Learner...\")\n",
    "stacking_ridge_search = RandomizedSearchCV(\n",
    "    stacking_regressor_ridge,\n",
    "    param_distributions=param_grid_meta_ridge,\n",
    "    n_iter=4,  # Number of alpha values\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_ridge_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Perform RandomizedSearchCV for Stacking Regressor with Lasso Meta-Learner\n",
    "print(\"Tuning Stacking Regressor with Lasso Meta-Learner...\")\n",
    "stacking_lasso_search = RandomizedSearchCV(\n",
    "    stacking_regressor_lasso,\n",
    "    param_distributions=param_grid_meta_lasso,\n",
    "    n_iter=4,  # Number of alpha values\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_lasso_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Retrieve Best Stacking Regressors\n",
    "best_stacking_lr = stacking_regressor_lr  # Original Stacking Regressor\n",
    "best_stacking_ridge = stacking_ridge_search.best_estimator_\n",
    "best_stacking_lasso = stacking_lasso_search.best_estimator_\n",
    "\n",
    "# ----------------------- Fit the Stacking Regressors -----------------------\n",
    "\n",
    "# Fit the original Stacking Regressor (if not already fitted)\n",
    "print(\"Fitting the original Stacking Regressor with LinearRegression...\")\n",
    "stacking_regressor_lr.fit(X_train, y_train_log)\n",
    "\n",
    "# The stacking regressors with Ridge and Lasso have already been fitted during RandomizedSearchCV\n",
    "\n",
    "# ----------------------- Make Predictions -----------------------\n",
    "\n",
    "# Predictions with original Stacking Regressor (LinearRegression)\n",
    "y_pred_log_stack_lr = stacking_regressor_lr.predict(X_test)\n",
    "y_pred_stack_lr = np.expm1(y_pred_log_stack_lr)  # Inverse log transformation\n",
    "\n",
    "# Predictions with Stacking Regressor (Ridge)\n",
    "y_pred_log_stack_ridge = best_stacking_ridge.predict(X_test)\n",
    "y_pred_stack_ridge = np.expm1(y_pred_log_stack_ridge)  # Inverse log transformation\n",
    "\n",
    "# Predictions with Stacking Regressor (Lasso)\n",
    "y_pred_log_stack_lasso = best_stacking_lasso.predict(X_test)\n",
    "y_pred_stack_lasso = np.expm1(y_pred_log_stack_lasso)  # Inverse log transformation\n",
    "\n",
    "# Inverse transform the test target variable\n",
    "y_test_actual = np.expm1(y_test_log)\n",
    "\n",
    "# ----------------------- Evaluation Function -----------------------\n",
    "\n",
    "def evaluate_model(y_true, y_pred, step_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nEvaluation metrics for {step_name}:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# ----------------------- Evaluate Individual Models -----------------------\n",
    "\n",
    "# Random Forest\n",
    "y_pred_log_rf = best_pipeline_rf.predict(X_test)\n",
    "y_pred_rf = np.expm1(y_pred_log_rf)\n",
    "evaluate_model(y_test_actual, y_pred_rf, \"Random Forest with Log-Transformed Target\")\n",
    "\n",
    "# XGBoost\n",
    "y_pred_log_xgb = best_pipeline_xgb.predict(X_test)\n",
    "y_pred_xgb = np.expm1(y_pred_log_xgb)\n",
    "evaluate_model(y_test_actual, y_pred_xgb, \"XGBoost with Log-Transformed Target\")\n",
    "\n",
    "# LightGBM\n",
    "y_pred_log_lgbm = best_pipeline_lgbm.predict(X_test)\n",
    "y_pred_lgbm = np.expm1(y_pred_log_lgbm)\n",
    "evaluate_model(y_test_actual, y_pred_lgbm, \"LightGBM with Log-Transformed Target\")\n",
    "\n",
    "# CatBoost\n",
    "y_pred_log_cat = best_pipeline_cat.predict(X_test)\n",
    "y_pred_cat = np.expm1(y_pred_log_cat)\n",
    "evaluate_model(y_test_actual, y_pred_cat, \"CatBoost with Log-Transformed Target\")\n",
    "\n",
    "# MLPRegressor\n",
    "y_pred_log_mlp = best_pipeline_mlp.predict(X_test)\n",
    "y_pred_mlp = np.expm1(y_pred_log_mlp)\n",
    "evaluate_model(y_test_actual, y_pred_mlp, \"MLPRegressor with Log-Transformed Target\")\n",
    "\n",
    "# ----------------------- Evaluate Stacking Regressors -----------------------\n",
    "\n",
    "# Original Stacking Regressor (LinearRegression)\n",
    "evaluate_model(y_test_actual, y_pred_stack_lr, \"Stacking Regressor with LinearRegression Meta-Learner\")\n",
    "\n",
    "# Stacking Regressor with Ridge Meta-Learner\n",
    "evaluate_model(y_test_actual, y_pred_stack_ridge, \"Stacking Regressor with Ridge Meta-Learner\")\n",
    "\n",
    "# Stacking Regressor with Lasso Meta-Learner\n",
    "evaluate_model(y_test_actual, y_pred_stack_lasso, \"Stacking Regressor with Lasso Meta-Learner\")\n",
    "\n",
    "# ----------------------- Cross-Validation for Stacking Regressors -----------------------\n",
    "\n",
    "# Cross-validation for original Stacking Regressor (LinearRegression)\n",
    "cv_scores_lr = cross_val_score(\n",
    "    stacking_regressor_lr,\n",
    "    X,\n",
    "    y_log,\n",
    "    cv=cv_strategy,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"\\nCross-validated R2 scores for Stacking Regressor with LinearRegression Meta-Learner: {cv_scores_lr}\")\n",
    "print(f\"Mean R2 score: {cv_scores_lr.mean():.4f}\")\n",
    "\n",
    "# Cross-validation for Stacking Regressor with Ridge Meta-Learner\n",
    "cv_scores_ridge = cross_val_score(\n",
    "    best_stacking_ridge,\n",
    "    X,\n",
    "    y_log,\n",
    "    cv=cv_strategy,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"\\nCross-validated R2 scores for Stacking Regressor with Ridge Meta-Learner: {cv_scores_ridge}\")\n",
    "print(f\"Mean R2 score: {cv_scores_ridge.mean():.4f}\")\n",
    "\n",
    "# Cross-validation for Stacking Regressor with Lasso Meta-Learner\n",
    "cv_scores_lasso = cross_val_score(\n",
    "    best_stacking_lasso,\n",
    "    X,\n",
    "    y_log,\n",
    "    cv=cv_strategy,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"\\nCross-validated R2 scores for Stacking Regressor with Lasso Meta-Learner: {cv_scores_lasso}\")\n",
    "print(f\"Mean R2 score: {cv_scores_lasso.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning and Logging Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3384.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Random_Forest with MAE: 98.86, RMSE: 132.66, R2: 0.2865\n",
      "Tuning and Logging XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3381.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost with MAE: 97.07, RMSE: 130.83, R2: 0.3060\n",
      "Tuning and Logging LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3404.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM with MAE: 98.91, RMSE: 132.00, R2: 0.2936\n",
      "Tuning and Logging CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3288.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged CatBoost with MAE: 96.19, RMSE: 129.95, R2: 0.3153\n",
      "Tuning and Logging MLPRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/moealhazmi/opt/anaconda3/envs/farms_claude/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3262.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged MLPRegressor with MAE: 101.14, RMSE: 134.47, R2: 0.2669\n",
      "Tuning Stacking Regressor with Ridge Meta-Learner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1393.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Stacking_Ridge with MAE: 96.93, RMSE: 130.32, R2: 0.3114\n",
      "Tuning Stacking Regressor with Lasso Meta-Learner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 3417.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Stacking_Lasso with MAE: 96.59, RMSE: 130.14, R2: 0.3133\n",
      "Logging Stacking Regressor with LinearRegression Meta-Learner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1923.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Stacking_LinearRegression with MAE: 96.56, RMSE: 130.13, R2: 0.3134\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor with LinearRegression Meta-Learner: [0.37332306 0.3904247  0.32319876 0.33443562 0.36374113]\n",
      "Mean R2 score: 0.3570\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor with Ridge Meta-Learner: [0.37387668 0.38996937 0.32336532 0.33558086 0.36687145]\n",
      "Mean R2 score: 0.3579\n",
      "\n",
      "Cross-validated R2 scores for Stacking Regressor with Lasso Meta-Learner: [0.37311147 0.39079672 0.32275963 0.33474495 0.36354371]\n",
      "Mean R2 score: 0.3570\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Importing Alternative Algorithms\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ----------------------- MLflow Integration -----------------------\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"Farms_Load_Estimation\")\n",
    "\n",
    "# ----------------------- Custom Transformer for Outlier Capping -----------------------\n",
    "\n",
    "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables=None, factor=1.5):\n",
    "        \"\"\"\n",
    "        Cap the outliers in specified variables using the IQR method.\n",
    "\n",
    "        Parameters:\n",
    "        - variables: list of column names to apply capping.\n",
    "        - factor: multiplier for the IQR to define the cap.\n",
    "        \"\"\"\n",
    "        self.variables = variables\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.cap_dict_ = {}\n",
    "        for var in self.variables:\n",
    "            Q1 = X[var].quantile(0.25)\n",
    "            Q3 = X[var].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_cap = Q1 - self.factor * IQR\n",
    "            upper_cap = Q3 + self.factor * IQR\n",
    "            self.cap_dict_[var] = (lower_cap, upper_cap)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_capped = X.copy()\n",
    "        for var in self.variables:\n",
    "            lower_cap, upper_cap = self.cap_dict_[var]\n",
    "            X_capped[var] = np.where(\n",
    "                X_capped[var] < lower_cap, lower_cap,\n",
    "                np.where(X_capped[var] > upper_cap, upper_cap, X_capped[var])\n",
    "            )\n",
    "        return X_capped\n",
    "\n",
    "# ----------------------- Data Preparation -----------------------\n",
    "\n",
    "# Load and prepare your features (assuming df_integrated contains the features)\n",
    "df_features = df_integrated.copy().drop(columns=['total_electrical_load_kw'])  # Now, df_integrated contains only HASAR data\n",
    "\n",
    "# Load your target variable\n",
    "df_target = df_integrated[['farm_id', 'total_electrical_load_kw']]\n",
    "\n",
    "# Merge features and target on 'farm_id'\n",
    "df_merged = df_integrated.copy()\n",
    "\n",
    "# List of new features to be created and the required columns for each\n",
    "new_features = {\n",
    "    'trees_per_hectare': ['productive_trees_count', 'total_area_hectares'],\n",
    "    'irrigation_intensity': ['irrigation_type_2.0', 'total_area_hectares'],\n",
    "    'well_density': ['well_count', 'total_area_hectares'],\n",
    "    'area_per_activity': ['total_area_hectares', 'activity_count']\n",
    "}\n",
    "\n",
    "# Check if required columns exist and create features if they do\n",
    "for feature_name, required_cols in new_features.items():\n",
    "    missing_cols = [col for col in required_cols if col not in df_merged.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Cannot create feature '{feature_name}' because the following columns are missing: {missing_cols}\")\n",
    "        # Assign default value or decide how to handle missing columns\n",
    "        df_merged[feature_name] = 0\n",
    "    else:\n",
    "        # Handle potential division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            if feature_name == 'trees_per_hectare':\n",
    "                df_merged[feature_name] = df_merged['productive_trees_count'] / df_merged['total_area_hectares']\n",
    "            elif feature_name == 'irrigation_intensity':\n",
    "                df_merged[feature_name] = df_merged['irrigation_type_2.0'] * df_merged['total_area_hectares']\n",
    "            elif feature_name == 'well_density':\n",
    "                # Ensure well_id is a count, not an identifier\n",
    "                if 'well_count' in df_merged.columns:\n",
    "                    df_merged[feature_name] = df_merged['well_count'] / df_merged['total_area_hectares']\n",
    "                else:\n",
    "                    print(f\"Cannot create feature '{feature_name}' because 'well_id' column is missing.\")\n",
    "                    df_merged[feature_name] = 0\n",
    "            elif feature_name == 'area_per_activity':\n",
    "                df_merged[feature_name] = df_merged['total_area_hectares'] / df_merged['activity_count']\n",
    "\n",
    "# Replace infinite and NaN values resulting from division by zero\n",
    "df_merged.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_merged.drop(columns=['farm_id', 'total_electrical_load_kw'])\n",
    "y = df_merged['total_electrical_load_kw']\n",
    "\n",
    "# ----------------------- Handle Outliers in the Target Variable -----------------------\n",
    "\n",
    "# Initialize OutlierCapper for the target variable\n",
    "target_capper = OutlierCapper(variables=['total_electrical_load_kw'], factor=1.5)\n",
    "y_capped = target_capper.fit_transform(X.assign(total_electrical_load_kw=y))['total_electrical_load_kw']\n",
    "\n",
    "# Apply log transformation\n",
    "y_log = np.log1p(y_capped)\n",
    "\n",
    "# Ensure that 'total_electrical_load_kw' is not present in X\n",
    "assert 'total_electrical_load_kw' not in X.columns\n",
    "\n",
    "# ----------------------- Split the Data -----------------------\n",
    "\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------- Preprocessing Pipelines -----------------------\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "variables_to_cap = numeric_features  # You can customize this list\n",
    "\n",
    "# Update the numeric transformer pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('outlier_capper', OutlierCapper(variables=variables_to_cap, factor=1.5)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# ----------------------- Define Base Learners Pipelines -----------------------\n",
    "\n",
    "# Random Forest pipeline\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# XGBoost pipeline\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "\n",
    "# LightGBM pipeline\n",
    "pipeline_lgbm = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LGBMRegressor(verbose=-1, random_state=42))\n",
    "])\n",
    "\n",
    "# CatBoost pipeline\n",
    "pipeline_cat = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', CatBoostRegressor(random_state=42, verbose=0))\n",
    "])\n",
    "\n",
    "# Neural Network pipeline\n",
    "pipeline_mlp = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', MLPRegressor(random_state=42, max_iter=500))\n",
    "])\n",
    "\n",
    "# ----------------------- Define Hyperparameter Grids -----------------------\n",
    "\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.7, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [5, 10, 15],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__num_leaves': [31, 50, 100],\n",
    "    'regressor__subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_grid_cat = {\n",
    "    'regressor__iterations': [500, 1000],\n",
    "    'regressor__depth': [4, 6, 8],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'regressor__hidden_layer_sizes': [(100,), (100, 50), (100, 100, 50)],\n",
    "    'regressor__activation': ['relu', 'tanh'],\n",
    "    'regressor__solver': ['adam', 'lbfgs'],\n",
    "    'regressor__alpha': [0.0001, 0.001, 0.01],\n",
    "    'regressor__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for meta-learners\n",
    "param_grid_meta_ridge = {\n",
    "    'final_estimator__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "param_grid_meta_lasso = {\n",
    "    'final_estimator__alpha': [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# ----------------------- Define Helper Functions for MLflow Logging -----------------------\n",
    "\n",
    "def train_and_log_model(model_name, pipeline, param_grid, X_train, y_train, X_test, y_test, cv, n_iter=10):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        input_example = X_train.iloc[:1]\n",
    "\n",
    "        \n",
    "        # Perform RandomizedSearchCV\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=n_iter,\n",
    "            cv=cv,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        # Log best parameters\n",
    "        mlflow.log_params(search.best_params_)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_log = search.predict(X_test)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "        y_test = np.expm1(y_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2_Score\", r2)\n",
    "        \n",
    "        # After making predictions, infer the signature\n",
    "        signature = infer_signature(input_example, y_pred)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(search.best_estimator_,\n",
    "                                artifact_path=model_name,\n",
    "                                signature=signature,\n",
    "                                input_example=input_example)\n",
    "                            \n",
    "        print(f\"Logged {model_name} with MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "        \n",
    "        return search.best_estimator_\n",
    "\n",
    "def train_and_log_stacking(model_name, stacking_regressor, X_train, y_train, X_test, y_test, cv):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        input_example = X_train.iloc[:1]\n",
    "        \n",
    "        # Fit the stacking regressor\n",
    "        stacking_regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_log = stacking_regressor.predict(X_test)\n",
    "        y_pred = np.expm1(y_pred_log)\n",
    "        y_test = np.expm1(y_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2_Score\", r2)\n",
    "        \n",
    "        # After making predictions, infer the signature\n",
    "        signature = infer_signature(input_example, y_pred[:1])\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            stacking_regressor,\n",
    "            artifact_path=model_name,\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "        \n",
    "        print(f\"Logged {model_name} with MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "        \n",
    "        return stacking_regressor\n",
    "\n",
    "# ----------------------- Hyperparameter Tuning with MLflow -----------------------\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Tuning and Logging Random Forest\n",
    "print(\"Tuning and Logging Random Forest...\")\n",
    "best_pipeline_rf = train_and_log_model(\n",
    "    model_name=\"Random_Forest\",\n",
    "    pipeline=pipeline_rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Tuning and Logging XGBoost\n",
    "print(\"Tuning and Logging XGBoost...\")\n",
    "best_pipeline_xgb = train_and_log_model(\n",
    "    model_name=\"XGBoost\",\n",
    "    pipeline=pipeline_xgb,\n",
    "    param_grid=param_grid_xgb,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Tuning and Logging LightGBM\n",
    "print(\"Tuning and Logging LightGBM...\")\n",
    "best_pipeline_lgbm = train_and_log_model(\n",
    "    model_name=\"LightGBM\",\n",
    "    pipeline=pipeline_lgbm,\n",
    "    param_grid=param_grid_lgbm,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Tuning and Logging CatBoost\n",
    "print(\"Tuning and Logging CatBoost...\")\n",
    "best_pipeline_cat = train_and_log_model(\n",
    "    model_name=\"CatBoost\",\n",
    "    pipeline=pipeline_cat,\n",
    "    param_grid=param_grid_cat,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy,\n",
    "    n_iter=5  # Reduced iterations for time efficiency\n",
    ")\n",
    "\n",
    "# Tuning and Logging MLPRegressor\n",
    "print(\"Tuning and Logging MLPRegressor...\")\n",
    "best_pipeline_mlp = train_and_log_model(\n",
    "    model_name=\"MLPRegressor\",\n",
    "    pipeline=pipeline_mlp,\n",
    "    param_grid=param_grid_mlp,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# ----------------------- Define the Enhanced Stacking Regressor -----------------------\n",
    "\n",
    "# Update estimators list to include all base learners\n",
    "estimators = [\n",
    "    ('rf', best_pipeline_rf),\n",
    "    ('xgb', best_pipeline_xgb),\n",
    "    ('lgbm', best_pipeline_lgbm),\n",
    "    ('cat', best_pipeline_cat),\n",
    "    ('mlp', best_pipeline_mlp)\n",
    "]\n",
    "\n",
    "# Original Stacking Regressor with LinearRegression as Meta-Learner\n",
    "stacking_regressor_lr = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LinearRegression(),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False  # Set to True if you want to include original features in the meta-learner\n",
    ")\n",
    "\n",
    "# ----------------------- Define and Tune Stacking Regressors with Ridge and Lasso Meta-Learners -----------------------\n",
    "\n",
    "# Define stacking regressors with Ridge and Lasso as meta-learners\n",
    "stacking_regressor_ridge = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(random_state=42),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "stacking_regressor_lasso = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Lasso(random_state=42),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# Perform RandomizedSearchCV for Stacking Regressor with Ridge Meta-Learner\n",
    "print(\"Tuning Stacking Regressor with Ridge Meta-Learner...\")\n",
    "stacking_ridge_search = RandomizedSearchCV(\n",
    "    stacking_regressor_ridge,\n",
    "    param_distributions=param_grid_meta_ridge,\n",
    "    n_iter=4,  # Number of alpha values\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_ridge_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Retrieve Best Stacking Regressor with Ridge\n",
    "best_stacking_ridge = stacking_ridge_search.best_estimator_\n",
    "\n",
    "# Log Stacking Regressor with Ridge\n",
    "train_and_log_stacking(\n",
    "    model_name=\"Stacking_Ridge\",\n",
    "    stacking_regressor=best_stacking_ridge,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy\n",
    ")\n",
    "\n",
    "# Perform RandomizedSearchCV for Stacking Regressor with Lasso Meta-Learner\n",
    "print(\"Tuning Stacking Regressor with Lasso Meta-Learner...\")\n",
    "stacking_lasso_search = RandomizedSearchCV(\n",
    "    stacking_regressor_lasso,\n",
    "    param_distributions=param_grid_meta_lasso,\n",
    "    n_iter=4,  # Number of alpha values\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_lasso_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Retrieve Best Stacking Regressor with Lasso\n",
    "best_stacking_lasso = stacking_lasso_search.best_estimator_\n",
    "\n",
    "# Log Stacking Regressor with Lasso\n",
    "train_and_log_stacking(\n",
    "    model_name=\"Stacking_Lasso\",\n",
    "    stacking_regressor=best_stacking_lasso,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy\n",
    ")\n",
    "\n",
    "# Optionally, log the original Stacking Regressor with LinearRegression\n",
    "print(\"Logging Stacking Regressor with LinearRegression Meta-Learner...\")\n",
    "train_and_log_stacking(\n",
    "    model_name=\"Stacking_LinearRegression\",\n",
    "    stacking_regressor=stacking_regressor_lr,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_log,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test_log,\n",
    "    cv=cv_strategy\n",
    ")\n",
    "\n",
    "# ----------------------- Evaluate Cross-Validation Metrics -----------------------\n",
    "\n",
    "with mlflow.start_run(run_name=\"Cross_Validation_Scoring\", nested=True):\n",
    "    # Cross-validation for original Stacking Regressor (LinearRegression)\n",
    "    cv_scores_lr = cross_val_score(\n",
    "        stacking_regressor_lr,\n",
    "        X,\n",
    "        y_log,\n",
    "        cv=cv_strategy,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    mlflow.log_metric(\"CV_Mean_R2_Score_LR\", cv_scores_lr.mean())\n",
    "    mlflow.log_metric(\"CV_STD_R2_Score_LR\", cv_scores_lr.std())\n",
    "    print(f\"\\nCross-validated R2 scores for Stacking Regressor with LinearRegression Meta-Learner: {cv_scores_lr}\")\n",
    "    print(f\"Mean R2 score: {cv_scores_lr.mean():.4f}\")\n",
    "\n",
    "    # Cross-validation for Stacking Regressor with Ridge Meta-Learner\n",
    "    cv_scores_ridge = cross_val_score(\n",
    "        best_stacking_ridge,\n",
    "        X,\n",
    "        y_log,\n",
    "        cv=cv_strategy,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    mlflow.log_metric(\"CV_Mean_R2_Score_Ridge\", cv_scores_ridge.mean())\n",
    "    mlflow.log_metric(\"CV_STD_R2_Score_Ridge\", cv_scores_ridge.std())\n",
    "    print(f\"\\nCross-validated R2 scores for Stacking Regressor with Ridge Meta-Learner: {cv_scores_ridge}\")\n",
    "    print(f\"Mean R2 score: {cv_scores_ridge.mean():.4f}\")\n",
    "\n",
    "    # Cross-validation for Stacking Regressor with Lasso Meta-Learner\n",
    "    cv_scores_lasso = cross_val_score(\n",
    "        best_stacking_lasso,\n",
    "        X,\n",
    "        y_log,\n",
    "        cv=cv_strategy,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    mlflow.log_metric(\"CV_Mean_R2_Score_Lasso\", cv_scores_lasso.mean())\n",
    "    mlflow.log_metric(\"CV_STD_R2_Score_Lasso\", cv_scores_lasso.std())\n",
    "    print(f\"\\nCross-validated R2 scores for Stacking Regressor with Lasso Meta-Learner: {cv_scores_lasso}\")\n",
    "    print(f\"Mean R2 score: {cv_scores_lasso.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9916</th>\n",
       "      <td>397.324349</td>\n",
       "      <td>423.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>315.032248</td>\n",
       "      <td>367.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>177.015708</td>\n",
       "      <td>80.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>510.535798</td>\n",
       "      <td>640.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9665</th>\n",
       "      <td>273.455654</td>\n",
       "      <td>286.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>285.087865</td>\n",
       "      <td>248.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>244.562842</td>\n",
       "      <td>398.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>142.099113</td>\n",
       "      <td>351.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>325.141120</td>\n",
       "      <td>323.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>183.459918</td>\n",
       "      <td>174.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted    true\n",
       "9916  397.324349  423.00\n",
       "5527  315.032248  367.05\n",
       "7534  177.015708   80.95\n",
       "543   510.535798  640.25\n",
       "9665  273.455654  286.10\n",
       "7913  285.087865  248.80\n",
       "5151  244.562842  398.00\n",
       "3095  142.099113  351.02\n",
       "1839  325.141120  323.40\n",
       "9920  183.459918  174.20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"predicted\":  np.expm1(stacking_regressor.predict(X_test)), \"true\": y_test_actual}).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='predicted', ylabel='true'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = pd.DataFrame({\"predicted\":  np.expm1( stacking_regressor.predict(X_test)), \"true\": y_test_actual})\n",
    "# plt.scatter(np.expm1( stacking_regressor.predict(X_test)), y_test_actual)\n",
    "results[(results[\"predicted\"]<800) & (results[\"true\"]<800)].plot.scatter(x=\"predicted\", y=\"true\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farms_claude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
